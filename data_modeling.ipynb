{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data, Data; Everywhere! \n",
    "+ Social Networks \n",
    "+ Cloud-Age Businesses\n",
    "+ LHC & SETI & Human Connectome Project\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Messy\n",
    "<img src=\"https://i.stack.imgur.com/4q9o2.png\" alt=\"xml_dear_god\" title=\"MESSY\" width=\"800px\" height=\"400px\" />\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Noisy\n",
    "<img src=\"http://strata2012.s3-website-us-east-1.amazonaws.com/images/Humidity.png\" alt=\"sensor_data\" title=\"NOISY\" width=\"800px\" height=\"400px\" />\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Yuge\n",
    "<img src=\"https://web-assets.domo.com/blog/wp-content/uploads/2015/08/15_domo_data-never-sleeps-3_final1.png\" alt=\"What Daily No\" title=\"YUGE\" width=\"600px\" height=\"800px\" />\n",
    "\n",
    "_Credit:_ <https://www.domo.com/blog/2015/08/data-never-sleeps-3-0/>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "# But What Is It Really Saying?!\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## From Here to There\n",
    "![prior_sample_post](bayes_nutshell.jpeg)\n",
    "\n",
    "\n",
    "## What Do Priors and Posteriors Look Like?\n",
    "![prob_dist](http://wikis.gm.fh-koeln.de/wiki_db_en/uploads/Topics/DataScience/probability.jpg)\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monty Hall Problem\n",
    "> Suppose you're on a game show, and you're given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what's behind the doors, opens another door, say No. 3, which has a goat. He then says to you, \"Do you want to pick door No. 2?\" Is it to your advantage to switch your choice?\n",
    "\n",
    ">_Whitaker, 1990, as quoted by vos Savant 1990a_\n",
    "\n",
    "\n",
    "## Assumptions Inherent in the Question\n",
    "> + The host must always open a door that was not picked by the contestant (Mueser and Granberg 1999).\n",
    "+ The host must always open a door to reveal a goat and never the car.\n",
    "+ The host must always offer the chance to switch between the originally chosen door and the remaining closed door."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pythonic Simulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "DOORS = (1,2,3)\n",
    "\n",
    "def doorpicker(strategy):\n",
    "    prize = random.choice(DOORS)\n",
    "    firstchoice = random.choice(DOORS)\n",
    "    if strategy == 'stay':\n",
    "        return firstchoice == prize\n",
    "    elif strategy == 'switch':\n",
    "        hostchoice = random.choice([x for x in DOORS if x != firstchoice and x != prize])\n",
    "        secondchoice = [x for x in DOORS if x != firstchoice and x != hostchoice]\n",
    "        assert len(secondchoice) == 1\n",
    "        return secondchoice[0] == prize\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "def counter(strategy, n):\n",
    "    return sum(doorpicker(strategy) for i in xrange(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I stay, I win 3340 prizes for 10000 tries\n",
      "If I switch, I win 6679 prizes for 10000 tries\n"
     ]
    }
   ],
   "source": [
    "strategies = ('stay', 'switch')\n",
    "n = 10000\n",
    "for s in strategies:\n",
    "    print('If I {0}, I win {1} prizes for {2} tries'.format(s, counter(s, n), n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Probability Flows and Sums, but also Multiplies\n",
    "\n",
    "> 20% of the patients in a screening population have Diseasitis. \n",
    "90% of the patients with Diseasitis turn the tongue depressor black, and 30% of the patients\n",
    "without Diseasitis turn the tongue depressor black. \n",
    "Given that a patient turned their tongue depressor black, what is the probability that they have Diseasitis?\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Bayes Theorem: Data As Evidence\n",
    "\n",
    "+ Ideal way to reason\n",
    "+ Difficult to apply in practice\n",
    "\n",
    "$$ P(A \\mid B) = \\frac{P(B \\mid A) \\, P(A)}{P(B)} $$\n",
    "\n",
    "$$ Prior = P(A) $$\n",
    "\n",
    "$$ Likelihood = \\frac{P(B \\mid A)}{P(B)} $$\n",
    "\n",
    "$$ Posterior = Prior \\hspace{2 mm} x \\hspace{2 mm} Likelihood $$\n",
    "\n",
    "\n",
    "![waterfall](https://i.imgur.com/eQh2qUt.png?0)\n",
    "\n",
    "![prior-posterior](https://i.imgur.com/CXsoZhA.png?0)\n",
    "\n",
    "In-Depth Tutorial: <https://arbital.com/p/bayes_rule/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation: Why Machine Learning\n",
    "\n",
    "\n",
    "## Two Views of Machine Learning\n",
    "\n",
    "> + Machine Learning seeks to **learn models of data**: define a **space of possible\n",
    "models; learn the parameters and structure of the models from data**; make\n",
    "predictions and decisions\n",
    "+ Machine Learning is a **toolbox of methods for processing data**: feed the data\n",
    "into one of many possible methods; choose methods that have **good theoretical\n",
    "or empirical performance**; make predictions and decisions\n",
    "\n",
    ">   _Zoubin Ghahramani, MLSS 2012_\n",
    "\n",
    "## Types of Tasks\n",
    "\n",
    "> Machine learning tasks are typically classified into three broad categories, depending on the nature of the learning \"signal\" or \"feedback\" available to a learning system. These are:\n",
    "\n",
    ">Supervised learning: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that maps inputs to outputs.\n",
    "Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\n",
    "Reinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent. The program is provided feedback in terms of rewards and punishments as it navigates its problem space.\n",
    "\n",
    "> _<https://en.wikipedia.org/wiki/Machine_learning#Types_of_problems_and_tasks>_\n",
    "\n",
    "\n",
    "## Categorization by Output\n",
    "\n",
    "+ Classification (Discrete Output)\n",
    "+ Regression (Continuous Output)\n",
    "+ Clustering (Unsupervised)\n",
    "+ Density Estimation (Spatial and Probabilistic)\n",
    "+ Dimensionality Reduction (Simplification)\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What are Models?\n",
    "Represent the key aspects of the real world in mathematics.\n",
    "## Examples:\n",
    "+ **Word Vectors**\n",
    "  ![gloVe](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/img/Turian-WordTSNE.png)\n",
    "  <br><br><br><br><br><br><br><br><br><br>\n",
    "+ **Homo Economicus: The Rational Human**\n",
    "  - **Action = max( Utility_Function(Situation) )**\n",
    "  <br><br><br><br><br><br><br><br><br><br>\n",
    "+ **Population Growth**\n",
    "  ![pop-growth](http://study.com/cimages/multimages/16/carrying_capacity.png)\n",
    "  <br><br><br><br><br><br><br><br><br><br>\n",
    "+ **Two-body Gravitational System**\n",
    "  ![two-body](https://upload.wikimedia.org/wikipedia/commons/0/0e/Orbit5.gif)\n",
    "  <br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "## Commonalities:\n",
    "### Data: Lives in a Space and is gathered from the real world\n",
    "### Predictions and Decisions: \n",
    "(if x=k, y=?) <br> or <br> (if x_0 = b, x_t = ?)\n",
    "### Model Components: Where the Magic Happens:\n",
    "#### Learning, Parameters and Structure \n",
    "    + (structure: DAG, Tree, Chain) \n",
    "    + (Learning: Gradient Descent, Bayes Rule, (What do SVMs use? What do Random Forests use?)) \n",
    "    + (Parameters: Matrices smashing into each other, Tree Nodes, Vectorspace Kernels)\n",
    "#### Theoretical and Empirical Performance \n",
    "    + theoretical: Asymptotic Bounds \n",
    "    + empirical: Past Error Rates\n",
    "    \n",
    "### Type of Models:\n",
    "+ Naive Bayes\n",
    "+ Random Forests\n",
    "+ Support Vector Machines\n",
    "+ Linear Regression\n",
    "+ Logistic Regression\n",
    "+ Neural Networks\n",
    "\n",
    "### Modern Requirements:\n",
    "Good Models:\n",
    "+ represent uncertainty in their structure and parameters \n",
    "+ adapt to the data and the problem statement automatically\n",
    "+ are robust against critical failure modes\n",
    "+ are capable of scaling to yuge data\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problems, Problems; Everywhere! \n",
    "\n",
    "### What Problems is ML good at?\n",
    "#### tl;dr wherever there's a lot of data\n",
    "+ Youtube Recommendations!\n",
    "+ Ad Clicks!\n",
    "+ Auto-Correct!\n",
    "+ Go & Chess & Pong!\n",
    "+ Traffic Jams!\n",
    "+ Cancer Diagnoses!\n",
    "+ Self-Driving Cars!\n",
    "+ Question Answering\n",
    "\n",
    "### What Problems does ML struggle with?\n",
    "+ Programming\n",
    "+ Legal Advice\n",
    "+ Surgery\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From iRobot to MyRobot\n",
    "> Probability theory is nothing but common sense reduced to calculation.\n",
    "> _Laplace, 1819_\n",
    "\n",
    "\n",
    "#### The Rules of Reasonable Thought:\n",
    "_HT: \"Probability Theory: The Logic of Science\" by E.T Jaynes_\n",
    "\n",
    "##### Logical Operations:\n",
    "+ Conjunction (AND)\n",
    "    **A . B**    \n",
    "+ Disjunction (OR)\n",
    "    **A + B**\n",
    "+ Negation (NOT)\n",
    "    **~A**\n",
    "+ Implication (IF THEN)\n",
    "    **=>**\n",
    "\n",
    "\n",
    "+ Degrees of plausibility are represented by real numbers.\n",
    "\n",
    "+ Qualitative correspondence with common sense:\n",
    "  - Conditional Probability: Statement A is only as plausabile as the evidence B makes it\n",
    "    + (A | B)\n",
    "  - Plausability relationships between statements can take many form\n",
    "    + (A | BC) or (A + B|CD )\n",
    "  - Metric Comparability\n",
    "    + (A | B) > (C | B)\n",
    "  - Probability of Evidence changing changes things:\n",
    "    + (A | C_1) > (A | C_0) AND (B | A C_1) == (B | A C_0) =>\n",
    "    (A B | C_1) > (A B | C_0)\n",
    "    AND\n",
    "    (~A | C_1) < (~A | C_0)\n",
    "    \n",
    "+ **Consistent** Reasoning:\n",
    "  - If a conclusion can be reasoned out in more than one way, \n",
    "  then every possible way must lead to the same result.\n",
    "  - A conclusion must be based on **all** of the evidence that is\n",
    "  relevant to a question. Arbitrarily ignoring some of\n",
    "  the information leads to biased, ideological conclusions.\n",
    "  - Equivalent **states of knowledge** are represented by equivalent plausibility assignments. \n",
    "  That is, if in two problems a robot’s state of knowledge is the same (except perhaps for \n",
    "  the labeling of the propositions), then it must assign the same \n",
    "  plausibilities in both."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fold",
   "language": "python",
   "name": "fold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
